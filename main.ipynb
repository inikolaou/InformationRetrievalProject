{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΕΡΩΤΗΜΑ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αποθήκευση των csv αρχείων σε dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('BX-Books.csv')\n",
    "users = pd.read_csv(\"BX-Users.csv\")\n",
    "ratings = pd.read_csv(\"BX-Book-Ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.merge(ratings, users, on='uid', how='outer', indicator='Exist')\n",
    "ratings = ratings[(ratings['Exist']=='both')]\n",
    "ratings = ratings[['uid', 'isbn', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.merge(ratings, books, on='isbn', how='outer', indicator='Exist')\n",
    "ratings = ratings[(ratings['Exist']=='both')]\n",
    "ratings = ratings[['uid', 'isbn', 'rating']]\n",
    "ratings['uid'] = pd.to_numeric(ratings['uid'], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123629</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169187</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169187</td>\n",
       "      <td>155704256X</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198013</td>\n",
       "      <td>0399135782</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42703</th>\n",
       "      <td>278260</td>\n",
       "      <td>0689821085</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42704</th>\n",
       "      <td>278330</td>\n",
       "      <td>0898861411</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42705</th>\n",
       "      <td>278621</td>\n",
       "      <td>1550390961</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42706</th>\n",
       "      <td>278713</td>\n",
       "      <td>0670528951</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42707</th>\n",
       "      <td>278714</td>\n",
       "      <td>0896101932</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42708 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid        isbn  rating\n",
       "0           2  0195153448     0.0\n",
       "1      123629  0002005018     9.0\n",
       "2      169187  0374157065     0.0\n",
       "3      169187  155704256X     0.0\n",
       "4      198013  0399135782     7.0\n",
       "...       ...         ...     ...\n",
       "42703  278260  0689821085     5.0\n",
       "42704  278330  0898861411     5.0\n",
       "42705  278621  1550390961     8.0\n",
       "42706  278713  0670528951     8.0\n",
       "42707  278714  0896101932     0.0\n",
       "\n",
       "[42708 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>Provides an introduction to classical myths pl...</td>\n",
       "      <td>['social science']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "      <td>['actresses']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>['1940-1949']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "      <td>['medical']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp; Company</td>\n",
       "      <td>A look at the incredibly well-preserved ancien...</td>\n",
       "      <td>['design']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134687</th>\n",
       "      <td>0312266448</td>\n",
       "      <td>The Military Quotation Book : Revised and Expa...</td>\n",
       "      <td>James Charlton</td>\n",
       "      <td>2002</td>\n",
       "      <td>Thomas Dunne Books</td>\n",
       "      <td>Contains more than 1,200 quotations about war,...</td>\n",
       "      <td>['reference']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134688</th>\n",
       "      <td>067161746X</td>\n",
       "      <td>The Bachelor Home Companion: A Practical Guide...</td>\n",
       "      <td>P.J. O'Rourke</td>\n",
       "      <td>1987</td>\n",
       "      <td>Pocket Books</td>\n",
       "      <td>A tongue-in-cheek survival guide for single pe...</td>\n",
       "      <td>['humor']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134689</th>\n",
       "      <td>0743203763</td>\n",
       "      <td>As Hogan Said . . . : The 389 Best Things Anyo...</td>\n",
       "      <td>Randy Voorhees</td>\n",
       "      <td>2000</td>\n",
       "      <td>Simon &amp; Schuster</td>\n",
       "      <td>Golf lovers will revel in this collection of t...</td>\n",
       "      <td>['humor']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134690</th>\n",
       "      <td>0767907566</td>\n",
       "      <td>All Elevations Unknown: An Adventure in the He...</td>\n",
       "      <td>Sam Lightner</td>\n",
       "      <td>2001</td>\n",
       "      <td>Broadway Books</td>\n",
       "      <td>A daring twist on the travel-adventure genre t...</td>\n",
       "      <td>['nature']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134691</th>\n",
       "      <td>0912333022</td>\n",
       "      <td>The Are You Being Served? Stories: 'Camping In...</td>\n",
       "      <td>Jeremy Lloyd</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kqed Books</td>\n",
       "      <td>These hilarious stories by the creator of publ...</td>\n",
       "      <td>['fiction']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134692 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              isbn                                         book_title  \\\n",
       "0       0195153448                                Classical Mythology   \n",
       "1       0002005018                                       Clara Callan   \n",
       "2       0060973129                               Decision in Normandy   \n",
       "3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       0393045218                             The Mummies of Urumchi   \n",
       "...            ...                                                ...   \n",
       "134687  0312266448  The Military Quotation Book : Revised and Expa...   \n",
       "134688  067161746X  The Bachelor Home Companion: A Practical Guide...   \n",
       "134689  0743203763  As Hogan Said . . . : The 389 Best Things Anyo...   \n",
       "134690  0767907566  All Elevations Unknown: An Adventure in the He...   \n",
       "134691  0912333022  The Are You Being Served? Stories: 'Camping In...   \n",
       "\n",
       "                 book_author  year_of_publication                publisher  \\\n",
       "0         Mark P. O. Morford                 2002  Oxford University Press   \n",
       "1       Richard Bruce Wright                 2001    HarperFlamingo Canada   \n",
       "2               Carlo D'Este                 1991          HarperPerennial   \n",
       "3           Gina Bari Kolata                 1999     Farrar Straus Giroux   \n",
       "4            E. J. W. Barber                 1999   W. W. Norton & Company   \n",
       "...                      ...                  ...                      ...   \n",
       "134687        James Charlton                 2002       Thomas Dunne Books   \n",
       "134688         P.J. O'Rourke                 1987             Pocket Books   \n",
       "134689        Randy Voorhees                 2000         Simon & Schuster   \n",
       "134690          Sam Lightner                 2001           Broadway Books   \n",
       "134691          Jeremy Lloyd                 1997               Kqed Books   \n",
       "\n",
       "                                                  summary            category  \n",
       "0       Provides an introduction to classical myths pl...  ['social science']  \n",
       "1       In a small town in Canada, Clara Callan reluct...       ['actresses']  \n",
       "2       Here, for the first time in paperback, is an o...       ['1940-1949']  \n",
       "3       Describes the great flu epidemic of 1918, an o...         ['medical']  \n",
       "4       A look at the incredibly well-preserved ancien...          ['design']  \n",
       "...                                                   ...                 ...  \n",
       "134687  Contains more than 1,200 quotations about war,...       ['reference']  \n",
       "134688  A tongue-in-cheek survival guide for single pe...           ['humor']  \n",
       "134689  Golf lovers will revel in this collection of t...           ['humor']  \n",
       "134690  A daring twist on the travel-adventure genre t...          ['nature']  \n",
       "134691  These hilarious stories by the creator of publ...         ['fiction']  \n",
       "\n",
       "[134692 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αποθήκευση των βιβλίων στην elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT = \"http://localhost:9200/\"\n",
    "es = Elasticsearch(timeout=600, hosts=ENDPOINT)\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This index already exists\n"
     ]
    }
   ],
   "source": [
    "if (not es.indices.exists(index=\"books\")):\n",
    "    with open('BX-Books.csv', encoding=\"utf8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        helpers.bulk(es, reader, index='books')\n",
    "else:\n",
    "    print(\"This index already exists\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δίνεται το αναγνωριστικό του χρήστη και το αλφαριθμητικό και επιστρέφεται το 10% των βιβλίων που ταιριάζουν καλύτερα με το αλφαριθμητικό σε φρίνουσα σειρά συνυπολογίζοντας την μετρική ομοιότητας της elasticsearch, καθώς και την βαθμολογία που έχει βάλει ο χρήστης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid = 123629, query = Canada\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user = int(input(\"Write id of user: \"))\n",
    "    if (users['uid'].isin([user]).any()):\n",
    "        break\n",
    "    else:\n",
    "        print(user, \"is not a valid id. Please input a valid user id!\")\n",
    "user_query = input(\"Write search term: \")\n",
    "print(\"uid =\", user, end=', ')\n",
    "print(\"query =\", user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0002005018']\n"
     ]
    }
   ],
   "source": [
    "good_new_ratings = ratings[(ratings[\"uid\"] == user) & (ratings['rating'] > 0)].sort_values(by='rating', ascending=False)\n",
    "good_rated_books = good_new_ratings['isbn'].tolist()\n",
    "print(good_rated_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_ex1 = es.search(index=\"books\", \n",
    "  body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": user_query,\n",
    "                        \"fields\": [\n",
    "                            \"summary^2\",\n",
    "                            \"title\"\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"should\": [\n",
    "                            {\n",
    "                                \"match\": {\n",
    "                                    \"isbn\": {\n",
    "                                        \"query\": book,\n",
    "                                        \"minimum_should_match\": \"1\",\n",
    "                                        \"boost\": 4.0\n",
    "                                    }\n",
    "                                }\n",
    "                            } for book in good_rated_books\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 10000\n",
    "  }\n",
    ")\n",
    "result = books_ex1[\"hits\"]\n",
    "total_hits = result['total']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0002005018', '0968067824', '0717282201', '052164626X', '0792271521', '0870444131', '1551580004', '0771040997', '0195417836', '0770418686', '0060183284', '0919891276', '082630706X', '0618197338', '1551053020', '0395442567', '0395544092', '0618131736', '0395711797', '0395681022', '0395636272', '0395383986', '0395636280', '0618117490', '0395926890', '0864923155', '1553373405', '039593916X', '0395939186']\n"
     ]
    }
   ],
   "source": [
    "result = books_ex1[\"hits\"][\"hits\"][:int(0.1*total_hits)]\n",
    "li = []\n",
    "for i in result:\n",
    "  res = i[\"_source\"]\n",
    "  li.append(res['isbn'])\n",
    "print(li)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΕΡΩΤΗΜΑ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θα αποθηκεύσουμε τους χρήστες σε ένα νέο dataframe. Στη συνέχεια θα το τροποποιήσουμε, ώστε να εφαρμόσουμε clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users = pd.read_csv(\"BX-Users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users['age'].fillna(users['age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_users['location'] = new_users['location'].str.split(',')\n",
    "location_info = pd.DataFrame(new_users[\"location\"].tolist()).fillna('').add_prefix('country_')\n",
    "new_users = pd.concat([new_users, location_info], axis=1)\n",
    "\n",
    "new_users.drop(['location', 'country_0', 'country_1', 'country_3', 'country_4', 'country_5', 'country_6', 'country_7', \n",
    "                'country_8'], axis=1, inplace=True)\n",
    "new_users.rename(columns={\"country_2\": \"country\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206442</th>\n",
       "      <td>278853</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206443</th>\n",
       "      <td>278855</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206444</th>\n",
       "      <td>278856</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206445</th>\n",
       "      <td>278857</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206446</th>\n",
       "      <td>278858</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206447 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid        age   country\n",
       "0            1  34.565775       usa\n",
       "1            2  18.000000       usa\n",
       "2            3  34.565775    russia\n",
       "3            4  17.000000  portugal\n",
       "4            5  34.565775       usa\n",
       "...        ...        ...       ...\n",
       "206442  278853  17.000000       usa\n",
       "206443  278855  50.000000       usa\n",
       "206444  278856  34.565775    canada\n",
       "206445  278857  34.565775       usa\n",
       "206446  278858  34.565775   ireland\n",
       "\n",
       "[206447 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, place in enumerate(new_users['country']):\n",
    "    place = place.strip()\n",
    "    if (place == '' or place == 'n/a'):\n",
    "        new_users.at[i, 'country'] = 'usa'\n",
    "    elif (place.isalpha() == False):\n",
    "        new_users.at[i, 'country'] = 'usa'\n",
    "    else:\n",
    "        new_users.at[i, 'country'] = place\n",
    "\n",
    "new_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age</th>\n",
       "      <th>country_a</th>\n",
       "      <th>country_aaa</th>\n",
       "      <th>country_aberdeenshire</th>\n",
       "      <th>country_acoruña</th>\n",
       "      <th>country_adsgfdr</th>\n",
       "      <th>country_afghanistan</th>\n",
       "      <th>country_africa</th>\n",
       "      <th>country_ahrensburg</th>\n",
       "      <th>...</th>\n",
       "      <th>country_yanhill</th>\n",
       "      <th>country_yemen</th>\n",
       "      <th>country_yorkshire</th>\n",
       "      <th>country_ysa</th>\n",
       "      <th>country_yugoslavia</th>\n",
       "      <th>country_yunling</th>\n",
       "      <th>country_z</th>\n",
       "      <th>country_zambia</th>\n",
       "      <th>country_zhengjiang</th>\n",
       "      <th>country_zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206442</th>\n",
       "      <td>278853</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206443</th>\n",
       "      <td>278855</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206444</th>\n",
       "      <td>278856</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206445</th>\n",
       "      <td>278857</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206446</th>\n",
       "      <td>278858</td>\n",
       "      <td>34.565775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206447 rows × 587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid        age  country_a  country_aaa  country_aberdeenshire  \\\n",
       "0            1  34.565775          0            0                      0   \n",
       "1            2  18.000000          0            0                      0   \n",
       "2            3  34.565775          0            0                      0   \n",
       "3            4  17.000000          0            0                      0   \n",
       "4            5  34.565775          0            0                      0   \n",
       "...        ...        ...        ...          ...                    ...   \n",
       "206442  278853  17.000000          0            0                      0   \n",
       "206443  278855  50.000000          0            0                      0   \n",
       "206444  278856  34.565775          0            0                      0   \n",
       "206445  278857  34.565775          0            0                      0   \n",
       "206446  278858  34.565775          0            0                      0   \n",
       "\n",
       "        country_acoruña  country_adsgfdr  country_afghanistan  country_africa  \\\n",
       "0                     0                0                    0               0   \n",
       "1                     0                0                    0               0   \n",
       "2                     0                0                    0               0   \n",
       "3                     0                0                    0               0   \n",
       "4                     0                0                    0               0   \n",
       "...                 ...              ...                  ...             ...   \n",
       "206442                0                0                    0               0   \n",
       "206443                0                0                    0               0   \n",
       "206444                0                0                    0               0   \n",
       "206445                0                0                    0               0   \n",
       "206446                0                0                    0               0   \n",
       "\n",
       "        country_ahrensburg  ...  country_yanhill  country_yemen  \\\n",
       "0                        0  ...                0              0   \n",
       "1                        0  ...                0              0   \n",
       "2                        0  ...                0              0   \n",
       "3                        0  ...                0              0   \n",
       "4                        0  ...                0              0   \n",
       "...                    ...  ...              ...            ...   \n",
       "206442                   0  ...                0              0   \n",
       "206443                   0  ...                0              0   \n",
       "206444                   0  ...                0              0   \n",
       "206445                   0  ...                0              0   \n",
       "206446                   0  ...                0              0   \n",
       "\n",
       "        country_yorkshire  country_ysa  country_yugoslavia  country_yunling  \\\n",
       "0                       0            0                   0                0   \n",
       "1                       0            0                   0                0   \n",
       "2                       0            0                   0                0   \n",
       "3                       0            0                   0                0   \n",
       "4                       0            0                   0                0   \n",
       "...                   ...          ...                 ...              ...   \n",
       "206442                  0            0                   0                0   \n",
       "206443                  0            0                   0                0   \n",
       "206444                  0            0                   0                0   \n",
       "206445                  0            0                   0                0   \n",
       "206446                  0            0                   0                0   \n",
       "\n",
       "        country_z  country_zambia  country_zhengjiang  country_zimbabwe  \n",
       "0               0               0                   0                 0  \n",
       "1               0               0                   0                 0  \n",
       "2               0               0                   0                 0  \n",
       "3               0               0                   0                 0  \n",
       "4               0               0                   0                 0  \n",
       "...           ...             ...                 ...               ...  \n",
       "206442          0               0                   0                 0  \n",
       "206443          0               0                   0                 0  \n",
       "206444          0               0                   0                 0  \n",
       "206445          0               0                   0                 0  \n",
       "206446          0               0                   0                 0  \n",
       "\n",
       "[206447 rows x 587 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_enc = pd.get_dummies(new_users,columns=[\"country\"])\n",
    "users_enc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργούμε 3 συστάδες για τους χρήστες ανάλογα με την ηλικία και την χώρα κατοικίας τους και τις αποθηκεύουμε στα αντίστοιχα dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 129053, 1: 49658, 2: 27736})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(3)\n",
    "label = kmeans.fit_predict(users_enc.drop(columns='uid'))\n",
    "cluster_count=Counter(label)\n",
    "cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "users1=new_users[kmeans.labels_==0]\n",
    "users2=new_users[kmeans.labels_==1]\n",
    "users3=new_users[kmeans.labels_==2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για κάθε συστάδα χρηστών φτίαχνουμε ένα dataframe στο οποίο βρίσκονται όλες οι αξιολογήσεις τους"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1=pd.merge(ratings, users1, on='uid', how='outer', indicator='Exist')\n",
    "ratings1=ratings1[(ratings1['Exist']=='both')]\n",
    "ratings1.drop(['age', 'country', 'Exist'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2=pd.merge(ratings, users2, on='uid', how='outer', indicator='Exist')\n",
    "ratings2=ratings2[(ratings2['Exist']=='both')]\n",
    "ratings2.drop(['age', 'country', 'Exist'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings3=pd.merge(ratings, users3, on='uid', how='outer', indicator='Exist')\n",
    "ratings3=ratings3[(ratings3['Exist']=='both')]\n",
    "ratings3.drop(['age', 'country', 'Exist'],axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια συμπληρώνουμε για κάθε βιβλίο που έχει αξιολογηθεί την μέση βαθμολογία που έχουν βάλει σε αυτό οι χρήστες της αντίστοιχης συστάδας"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1 = ratings1.groupby(['isbn'])['rating'].mean().reset_index(name='average')\n",
    "books1 = pd.merge(ratings1, books, on='isbn', how='outer')\n",
    "ratings1 = ratings1[(ratings1['average'] > 0)].sort_values(by='average', ascending=False)\n",
    "ratings1 = ratings1['isbn'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2 = ratings2.groupby(['isbn'])['rating'].mean().reset_index(name='average')\n",
    "books2 = pd.merge(ratings2, books, on='isbn', how='outer')\n",
    "ratings2 = ratings2[(ratings2['average'] > 0)].sort_values(by='average', ascending=False)\n",
    "ratings2 = ratings2['isbn'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings3 = ratings3.groupby(['isbn'])['rating'].mean().reset_index(name='average')\n",
    "books3 = pd.merge(ratings3, books, on='isbn', how='outer')\n",
    "ratings3 = ratings3[(ratings3['average'] > 0)].sort_values(by='average', ascending=False)\n",
    "ratings3 = ratings3['isbn'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cluster = 0\n",
    "good_rated_books2 = good_rated_books.copy()\n",
    "if (users1['uid'].isin([user]).any()):\n",
    "    user_cluster = 1\n",
    "    good_rated_books2.extend(ratings1)\n",
    "elif (users2['uid'].isin([user]).any()):\n",
    "    user_cluster = 2\n",
    "    good_rated_books2.extend(ratings2)\n",
    "elif (users3['uid'].isin([user]).any()):\n",
    "    user_cluster = 3\n",
    "    good_rated_books2.extend(ratings3)\n",
    "good_rated_books2 = good_rated_books2[:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_ex2 = es.search(index=\"books\", \n",
    "  body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": user_query,\n",
    "                        \"fields\": [\n",
    "                            \"summary^2\",\n",
    "                            \"title\"\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"should\": [\n",
    "                            {\n",
    "                                \"match\": {\n",
    "                                    \"isbn\": {\n",
    "                                        \"query\": book,\n",
    "                                        \"minimum_should_match\": \"1\",\n",
    "                                        \"boost\": 4.0\n",
    "                                    }\n",
    "                                }\n",
    "                            } for book in good_rated_books2\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 10000\n",
    "  }\n",
    ")\n",
    "result = books_ex2[\"hits\"]\n",
    "total_hits = result['total']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0871238829', '0143312146', '0002005018', '0743223527', '1583485473', '0595206263', '0968288308', '1879384493', '0966986105', '0840734530', '059043893X', '0345391691', '0060973897', '1573225126', '0679310002', '0440225078', '193072229X', '0609605925', '1563411148', '0945397410', '0140274154', '0345409469', '0140304770', '0345307674', '0394404289', '0380012774', '0743444051', '0671619055', '0743412273', '0307001385', '0679439242', '0816614024', '1587991039', '0440512158', '0765342294', '0316919896', '0373871864', '0515107662', '0140286780', '0380810336', '0451456718', '0812533550', '0836220889', '0060923717', '0345421825', '0590629808', '0590956159', '0671517643', '0312311354', '034536662X', '0786404019', '0446603775', '0553277537', '0399147101', '0500280673', '0440228204', '0026890380', '0140309578', '0312180624', '1561794708', '1566840287', '0060504080', '1573226106', '0517576988', '0451201515', '1583940634', '0449212858', '0140344438', '0142000345', '0376026138', '0440226848', '0679824111', '0743222261', '076422249X', '0802137008', '0399226907', '0671705091', '0399145869', '0688009387', '0486270610', '0679723226', '0736909672', '0965881199', '0375413278', '0786869011', '0140266909', '0451524063', '0373166931', '0449005844', '0142000671', '0898861098', '0755200381', '0884270610', '0439313899', '0883681056', '1561840092', '1855381125', '0064472574', '0380003821', '0440414539', '0312985207', '0425122956', '0743454146', '087542791X', '0451525884', '0689710682', '0553577123', '0553279025', '0486268705', '0385333706', '0385720327', '0771079567', '1894294424', '0345326342', '0671625837', '0679734406', '0761121323', '096774590X', '042514545X', '0553568779', '1853260274', '0140043519', '0671881884', '1567312292', '0064403688', '0345403959', '0380718839', '044990542X', '0553096060', '1556618662', '1568360428']\n"
     ]
    }
   ],
   "source": [
    "result = books_ex2[\"hits\"][\"hits\"][:int(0.1*total_hits)]\n",
    "li = []\n",
    "for i in result:\n",
    "  res = i[\"_source\"]\n",
    "  li.append(res['isbn'])\n",
    "print(li)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΕΡΩΤΗΜΑ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model , Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αρχικά κάνουμε preprocessing στις περιλήψεις των βιβλίων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_books= books[['summary']]\n",
    "summaries = new_books.summary.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια μέσω της gensim μετατρέπουμε κάθε λέξη σε διάνυσμα και προσθέτουμε τα διανύσματα των λέξεων για κάθε περίληψη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13862105, 17864510)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "model.build_vocab(summaries, progress_per = 1000)\n",
    "model.train(summaries, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dniko\\AppData\\Local\\Temp\\ipykernel_9956\\1344823315.py:8: RuntimeWarning: invalid value encountered in add\n",
      "  arr += model.wv.get_vector(word)\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "i = 0\n",
    "j = 0\n",
    "arr = np.empty([100, ], dtype = np.float32)\n",
    "for review in summaries:\n",
    "    for word in review:\n",
    "        try:\n",
    "            arr += model.wv.get_vector(word)\n",
    "            j += 1\n",
    "        except Exception as e:\n",
    "            arr += np.zeros([100, ])\n",
    "            i += 1\n",
    "    li.append(arr)\n",
    "    arr = np.empty([100, ], dtype = np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για κάθε μια από τις συστάδες χωρίζουμε τα βιβλία με αξιολογήσεις, από αυτά που δεν έχουν αξιολογηθεί"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_books1 = books1\n",
    "new_books1['summary']=li\n",
    "new_books2 = books2\n",
    "new_books2['summary']=li\n",
    "new_books3 = books3\n",
    "new_books3['summary']=li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_books1 = new_books1[new_books1['average'].notna()]\n",
    "unrated_books1 = new_books1[new_books1['average'].isna()]\n",
    "unrated_books1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_books2 = new_books2[new_books2['average'].notna()]\n",
    "unrated_books2 = new_books2[new_books2['average'].isna()]\n",
    "unrated_books2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_books3 = new_books3[new_books3['average'].notna()]\n",
    "unrated_books3 = new_books3[new_books3['average'].isna()]\n",
    "unrated_books3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κανονικοποιούμε τα δεδομένα και τα μετατρέπουμε σε κατάλληλη μορφή για να εισέλθουν στο νευρωνικό δίκτυο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = rated_books1[['summary']]\n",
    "X1_pred = unrated_books1[['summary']]\n",
    "y1 = rated_books1['average']\n",
    "\n",
    "X1 = np.array(X1.summary.tolist()).reshape(-1, len(X1.summary[0]))\n",
    "X1_pred = np.array(X1_pred.summary.tolist()).reshape(-1, len(X1_pred.summary[0]))\n",
    "y1 = np.array(y1)\n",
    "\n",
    "\n",
    "X1_pred[np.isnan(X1_pred)] = 0.0001\n",
    "X1[np.isnan(X1)] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -1000000000000000\n",
    "l = -1000000000000000\n",
    "for i in X1:\n",
    "    if i.max() > m:\n",
    "        m = i.max()\n",
    "for i in y1:\n",
    "    if i.max() > l:\n",
    "        l = i.max()\n",
    "\n",
    "X1 = X1 / m\n",
    "\n",
    "m = -1000000000000000\n",
    "l = -1000000000000000\n",
    "for i in X1_pred:\n",
    "    if i.max() > m:\n",
    "        m = i.max()\n",
    "for i in y1:\n",
    "    if i.max() > l:\n",
    "        l = i.max()\n",
    "\n",
    "X1_pred = X1_pred / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = rated_books2[['summary']]\n",
    "X2_pred = unrated_books2[['summary']]\n",
    "y2 = rated_books2['average']\n",
    "\n",
    "X2 = np.array(X2.summary.tolist()).reshape(-1, len(X2.summary[0]))\n",
    "X2_pred = np.array(X2_pred.summary.tolist()).reshape(-1, len(X2_pred.summary[0]))\n",
    "y2 = np.array(y2)\n",
    "\n",
    "\n",
    "X2_pred[np.isnan(X2_pred)] = 0.0001\n",
    "X2[np.isnan(X2)] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -1000000000000000\n",
    "l = -1000000000000000\n",
    "for i in X2:\n",
    "    if i.max() > m:\n",
    "        m = i.max()\n",
    "for i in y2:\n",
    "    if i.max() > l:\n",
    "        l = i.max()\n",
    "\n",
    "X2 = X2 / m\n",
    "\n",
    "m = -1000000000000000\n",
    "l = -1000000000000000\n",
    "for i in X2_pred:\n",
    "    if i.max() > m:\n",
    "        m = i.max()\n",
    "for i in y2:\n",
    "    if i.max() > l:\n",
    "        l = i.max()\n",
    "\n",
    "X2_pred = X2_pred / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = rated_books3[['summary']]\n",
    "X3_pred = unrated_books3[['summary']]\n",
    "y3 = rated_books3['average']\n",
    "\n",
    "X3 = np.array(X3.summary.tolist()).reshape(-1, len(X3.summary[0]))\n",
    "X3_pred = np.array(X3_pred.summary.tolist()).reshape(-1, len(X3_pred.summary[0]))\n",
    "y3 = np.array(y3)\n",
    "\n",
    "\n",
    "X3_pred[np.isnan(X3_pred)] = 0.0001\n",
    "X3[np.isnan(X3)] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -1000000000000000\n",
    "l = -1000000000000000\n",
    "for i in X3:\n",
    "    if i.max() > m:\n",
    "        m = i.max()\n",
    "for i in y3:\n",
    "    if i.max() > l:\n",
    "        l = i.max()\n",
    "\n",
    "X3 = X3 / m\n",
    "\n",
    "m = -1000000000000000\n",
    "l = -1000000000000000\n",
    "for i in X3_pred:\n",
    "    if i.max() > m:\n",
    "        m = i.max()\n",
    "for i in y3:\n",
    "    if i.max() > l:\n",
    "        l = i.max()\n",
    "\n",
    "X3_pred = X3_pred / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.rint(y1).astype(np.int64)\n",
    "y2 = np.rint(y2).astype(np.int64)\n",
    "y3 = np.rint(y3).astype(np.int64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εκπαιδεύουμε το νευρωνικό μας δίκτυο ώστε να δέχεται σαν είσοδο τα διανύσματα των περιλήψεων και να προβλέπει την αξιολόγηση των βιβλίων με βάση τις ήδη υπάρχουσες αξιολογήσεις κάθε συστάδας"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "467/467 [==============================] - 3s 3ms/step - loss: 2.1280 - accuracy: 0.3152\n",
      "Epoch 2/3\n",
      "467/467 [==============================] - 1s 3ms/step - loss: 2.0828 - accuracy: 0.3155\n",
      "Epoch 3/3\n",
      "467/467 [==============================] - 1s 3ms/step - loss: 2.0798 - accuracy: 0.3155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f5f38d0f0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model1 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(100, ), activation='relu'),\n",
    "    keras.layers.Dense(11, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model1.fit(X1, y1, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3744/3744 [==============================] - 8s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dniko\\AppData\\Local\\Temp\\ipykernel_9956\\3444542414.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unrated_books1['average'] = predicted_average1\n"
     ]
    }
   ],
   "source": [
    "new_average1=model1.predict(X1_pred)\n",
    "predicted_average1 = [np.argmax(i) for i in new_average1]\n",
    "unrated_books1['average'] = predicted_average1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "172/172 [==============================] - 1s 2ms/step - loss: 2.1484 - accuracy: 0.3482\n",
      "Epoch 2/3\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 1.9885 - accuracy: 0.3526\n",
      "Epoch 3/3\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.9808 - accuracy: 0.3526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f3105bbb0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(100, ), activation='relu'),\n",
    "    keras.layers.Dense(11, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model2.fit(X2, y2, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4038/4038 [==============================] - 7s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dniko\\AppData\\Local\\Temp\\ipykernel_9956\\3729225543.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unrated_books2['average'] = predicted_average2\n"
     ]
    }
   ],
   "source": [
    "new_average2=model2.predict(X2_pred)\n",
    "predicted_average2 = [np.argmax(i) for i in new_average2]\n",
    "unrated_books2['average'] = predicted_average2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "137/137 [==============================] - 1s 2ms/step - loss: 2.2022 - accuracy: 0.2969\n",
      "Epoch 2/3\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 2.0282 - accuracy: 0.3145\n",
      "Epoch 3/3\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.0178 - accuracy: 0.3147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f32fa8850>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(100, ), activation='relu'),\n",
    "    keras.layers.Dense(11, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model3.fit(X3, y3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4073/4073 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dniko\\AppData\\Local\\Temp\\ipykernel_9956\\3209853018.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unrated_books3['average'] = predicted_average3\n"
     ]
    }
   ],
   "source": [
    "new_average3=model3.predict(X3_pred)\n",
    "predicted_average3 = [np.argmax(i) for i in new_average3]\n",
    "unrated_books3['average'] = predicted_average3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Προσθέτουμε τις προβλεπόμενες βαθμολογίες κάθε βιβλίου "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_books1 = pd.concat([rated_books1, unrated_books1], axis=0)\n",
    "final_books1.drop('summary', axis=1, inplace=True)\n",
    "b1=books1[['isbn', 'summary']]\n",
    "final_books1= pd.merge(b1, final_books1, on='isbn', how='outer')\n",
    "final_books1 = final_books1[(final_books1['average'] > 0)].sort_values(by='average', ascending=False)\n",
    "final_books1 = final_books1['isbn'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_books2 = pd.concat([rated_books2, unrated_books2], axis=0)\n",
    "final_books2.drop('summary', axis=1, inplace=True)\n",
    "b2=books2[['isbn', 'summary']]\n",
    "final_books2= pd.merge(b2, final_books2, on='isbn', how='outer')\n",
    "final_books2 = final_books2[(final_books2['average'] > 0)].sort_values(by='average', ascending=False)\n",
    "final_books2 = final_books2['isbn'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_books3 = pd.concat([rated_books3, unrated_books3], axis=0)\n",
    "final_books3.drop('summary', axis=1, inplace=True)\n",
    "b3=books3[['isbn', 'summary']]\n",
    "final_books3= pd.merge(b3, final_books3, on='isbn', how='outer')\n",
    "final_books3 = final_books3[(final_books3['average'] > 0)].sort_values(by='average', ascending=False)\n",
    "final_books3 = final_books3['isbn'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_rated_books3 = good_rated_books.copy()\n",
    "if (user_cluster == 1):\n",
    "    good_rated_books3.extend(final_books1)\n",
    "elif (user_cluster == 2):\n",
    "    good_rated_books3.extend(final_books2)\n",
    "elif (user_cluster == 3):\n",
    "    good_rated_books3.extend(final_books3)\n",
    "good_rated_books3 = good_rated_books3[:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_ex3 = es.search(index=\"books\", \n",
    "  body = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": user_query,\n",
    "                        \"fields\": [\n",
    "                            \"summary^2\",\n",
    "                            \"title\"\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"should\": [\n",
    "                            {\n",
    "                                \"match\": {\n",
    "                                    \"isbn\": {\n",
    "                                        \"query\": book,\n",
    "                                        \"minimum_should_match\": \"1\",\n",
    "                                        \"boost\": 4.0\n",
    "                                    }\n",
    "                                }\n",
    "                            } for book in good_rated_books3\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"size\": 10000\n",
    "  }\n",
    ")\n",
    "result = books_ex3[\"hits\"]\n",
    "total_hits = result['total']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0871238829', '0143312146', '0002005018', '0743223527', '1583485473', '0595206263', '0968288308', '1879384493', '0964778319', '0966986105', '0840734530', '059043893X', '0345391691', '0060973897', '1573225126', '0679310002', '0440225078', '193072229X', '0609605925', '1563411148', '0945397410', '0140274154', '0345409469', '0140304770', '0345307674', '0394404289', '0380012774', '0743444051', '0671619055', '0743412273', '0307001385', '0679439242', '0816614024', '1587991039', '0440512158', '0765342294', '0316919896', '0373871864', '0440168724', '0515107662', '0140286780', '0380810336', '0451456718', '0812533550', '0836220889', '0060923717', '0345421825', '0590629808', '0590956159', '0671517643', '0312311354', '034536662X', '0786404019', '0446603775', '0553277537', '0399147101', '0500280673', '0440228204', '0026890380', '0140309578', '0312180624', '1561794708', '0060504080', '1573226106', '0440183057', '0517576988', '0451201515', '1583940634', '0449212858', '0140344438', '0142000345', '0376026138', '0679824111', '0743222261', '076422249X', '0802137008', '0399226907', '0671705091', '0399145869', '0688009387', '0486270610', '0679723226', '0736909672', '0965881199', '0375413278', '0786869011', '0140266909', '0451524063', '0449005844', '0142000671', '088029261X', '0898861098', '0755200381', '0884270610', '0883681056', '1561840092', '1855381125', '0064472574', '0380003821', '0440414539', '0312985207', '0425122956', '0743454146', '087542791X', '0451525884', '0689710682', '0553577123', '0553279025', '0486268705', '0385333706', '0385720327', '0771079567', '1894294424', '0345326342', '0553205803', '0671625837', '0679734406', '0761121323', '096774590X', '042514545X', '0553568779', '1853260274', '0140043519', '0380978407', '0671881884', '0345403959', '0380718839', '044990542X', '0553096060', '1556618662', '0140446745']\n"
     ]
    }
   ],
   "source": [
    "result = books_ex3[\"hits\"][\"hits\"][:int(0.1*total_hits)]\n",
    "li = []\n",
    "for i in result:\n",
    "  res = i[\"_source\"]\n",
    "  li.append(res['isbn'])\n",
    "print(li)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "information_retrieval-kV2Uir7P",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b99458138f5801e6104852ec902d32e7a2b60705b186273063a64d026d406782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
